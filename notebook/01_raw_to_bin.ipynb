{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a672b4-0cc2-40b6-ace3-e61faea3634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: readBrukerFlexData\n",
      "\n",
      "R[write to console]: Loading required package: MALDIquant\n",
      "\n",
      "R[write to console]: \n",
      "This is MALDIquant version 1.22.3\n",
      "Quantitative Analysis of Mass Spectrometry Data\n",
      " See ‘?MALDIquant’ for more information about this package.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import rpy2.robjects as robjects\n",
    "\n",
    "robjects.r('''\n",
    "require(\"readBrukerFlexData\")\n",
    "require(\"MALDIquant\")\n",
    "readBruker <- function(path_, out_path_) {\n",
    "    sample <- readBrukerFlexDir(path_, removeCalibrationScans = TRUE,\n",
    "                                removeMetaData = FALSE, useHpc = TRUE, useSpectraNames = TRUE,                                                        \n",
    "                                filterZeroIntensities = FALSE, verbose = FALSE)\n",
    "        \n",
    "    m <- sample[[1]][[1]]$mass\n",
    "    i <- sample[[1]][[1]]$intensity\n",
    "        \n",
    "    #Basic Preprocessing\n",
    "    # (In this version the data was NOT transformed and normalized. That will hapen later in python)\n",
    "    spectra <- createMassSpectrum(mass = m, intensity = i)\n",
    "    spectra <- transformIntensity(spectra, method=\"sqrt\")\n",
    "    spectra <- smoothIntensity(spectra, method=\"SavitzkyGolay\", halfWindowSize=10)\n",
    "    spectra <- removeBaseline(spectra, method=\"SNIP\", iterations=20)\n",
    "    spectra <- calibrateIntensity(spectra, method=\"TIC\")\n",
    "    spectra <- trim(spectra, range=c(2000, 20000))\n",
    "\n",
    "    #pks <- detectPeaks(spectra, method=\"MAD\", halfWindowSize=20, SNR=4)\n",
    "    pks <- spectra\n",
    "\n",
    "    mass <- mass(pks)\n",
    "    intensity <- intensity(pks)\n",
    "    small_dataframe <- data.frame(mass, intensity, stringsAsFactors = FALSE)\n",
    "\n",
    "    write.table(small_dataframe, out_path_, row.names = F, col.names = F)\n",
    "    }\n",
    "    ''')\n",
    "read_bruker = robjects.globalenv['readBruker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cdfe3f7-8289-4946-a10e-e5dd08ab416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def folder_scan(raw_dir: str) -> dict:\n",
    "    file_exist_dic = {}\n",
    "    raw_file_path = os.path.join(raw_dir, '*', '*')\n",
    "    raw_file_list = glob.glob(raw_file_path)\n",
    "    for filepath in raw_file_list:\n",
    "        species_name, sample_number = filepath.split(os.sep)[-2:]\n",
    "        if species_name not in file_exist_dic.keys():\n",
    "            file_exist_dic[species_name] = set()\n",
    "        file_exist_dic[species_name].add(sample_number)\n",
    "    print(f'File scan done.')\n",
    "    \n",
    "    return file_exist_dic\n",
    "\n",
    "\n",
    "def preprocessing(raw_dir: str, preprocessed_dir: str, file_exist_dic: dict) -> None:\n",
    "    for species in file_exist_dic.keys():\n",
    "        raw_path_species = os.path.join(raw_dir, species)\n",
    "        preprocessed_path = os.path.join(preprocessed_dir, species)\n",
    "        os.makedirs(preprocessed_path, exist_ok=True)\n",
    "        for sample_number in file_exist_dic[species]:\n",
    "            raw_path = os.path.join(raw_path_species, sample_number)\n",
    "            preprocessed_filepath = os.path.join(preprocessed_path, sample_number)\n",
    "            preprocessed_filepath = f'{preprocessed_filepath}.txt'\n",
    "\n",
    "            if os.path.exists(preprocessed_filepath):\n",
    "                #print(f'Preprocessing {preprocessed_filepath} already exist.')\n",
    "                continue\n",
    "            \n",
    "            print(f'New raw file: {raw_path} found.')\n",
    "            read_bruker(raw_path, preprocessed_filepath)\n",
    "\n",
    "            try:\n",
    "                read_bruker(raw_path, preprocessed_filepath)\n",
    "                print(f'Preprocessing {preprocessed_filepath} done.')\n",
    "            except:\n",
    "                print(f'Preprocessing of {raw_path} fail.')\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "def bin_vectorize(preprocessed_file: str, binned_file: str, bin_size: int) -> None:\n",
    "    spectra = pd.read_csv(preprocessed_file, sep=' ', index_col=False, header=None).to_numpy()\n",
    "    combined_times = spectra[:, 0]\n",
    "    min_range = min(2000, np.min(combined_times))\n",
    "    max_range = max(20000, np.max(combined_times))\n",
    "\n",
    "    _, bin_edges_ = np.histogram(combined_times, bin_size, range=(min_range, max_range))\n",
    "\n",
    "    times = spectra[:, 0]\n",
    "    indices = np.digitize(times, bin_edges_, right=True)\n",
    "    \n",
    "    valid = (indices >= 1) & (indices <= bin_size)\n",
    "    spectrum = spectra[valid]\n",
    "    \n",
    "    # Need to update indices to ensure that the first bin is at\n",
    "    # position zero.\n",
    "    indices = indices[valid] - 1 \n",
    "    identity = np.eye(bin_size)\n",
    "    \n",
    "    vec = np.sum(identity[indices] * spectra[:, 1][:, np.newaxis], axis=0)\n",
    "    np.savetxt(binned_file, vec, delimiter=\",\")\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def binning(preprocessed_dir: str, binned_dir: str, file_todo_dic: dict, bin_size: int) -> None:\n",
    "    for species in file_todo_dic.keys():\n",
    "        preprocessed_path_species = os.path.join(preprocessed_dir, species)\n",
    "        binned_path = os.path.join(binned_dir, species)\n",
    "        os.makedirs(binned_path, exist_ok=True)\n",
    "        for sample_number in file_todo_dic[species]:\n",
    "            preprocessed_file_path = os.path.join(preprocessed_path_species, sample_number)\n",
    "            sample_outpath = os.path.join(binned_path, sample_number)\n",
    "\n",
    "            if os.path.exists(sample_outpath):\n",
    "                print(f'Preprocessing {sample_outpath} already exist.')\n",
    "                continue\n",
    "            \n",
    "            print(f'New preprocessed file: {preprocessed_file_path} found.')\n",
    "            bin_vectorize(preprocessed_file_path, sample_outpath, bin_size)\n",
    "            \n",
    "            try:\n",
    "                bin_vectorize(preprocessed_file_path, sample_outpath, bin_size)\n",
    "                print(f'Binning {sample_outpath} done.')\n",
    "            except:\n",
    "                print(f'Binning of {preprocessed_file_path} fail.')\n",
    "\n",
    "\n",
    "    \n",
    "def scan_preprocessing(bin_size: int) -> None:\n",
    "    raw_dir = os.path.join('..', 'data', 'raw')\n",
    "    preprocessed_dir = os.path.join('..', 'data', 'preprocessed')\n",
    "    binned_dir = os.path.join('..', 'data', f'binned_{str(bin_size)}')\n",
    "    os.makedirs(raw_dir, exist_ok=True)\n",
    "    os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "    os.makedirs(binned_dir, exist_ok=True)\n",
    "\n",
    "    file_exist_dic = folder_scan(raw_dir)\n",
    "    print(file_exist_dic)\n",
    "    preprocessing(raw_dir, preprocessed_dir, file_exist_dic)\n",
    "\n",
    "    preprocessed_exist_dic = folder_scan(preprocessed_dir)\n",
    "    print(preprocessed_exist_dic)\n",
    "    _ = binning(preprocessed_dir, binned_dir, preprocessed_exist_dic, bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97be23c3-c880-4ec2-8b3f-e334695206a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw file scan done.\n",
      "{'Escherichia_coli': {'example12', 'example1'}}\n",
      "Raw file scan done.\n",
      "{'Escherichia_coli': {'example1.txt', 'example12.txt'}}\n",
      "New raw file: ../data/preprocessed/Escherichia_coli/example1.txt found.\n",
      "Binning ../data/binned_6000/Escherichia_coli/example1.txt done.\n",
      "New raw file: ../data/preprocessed/Escherichia_coli/example12.txt found.\n",
      "Binning ../data/binned_6000/Escherichia_coli/example12.txt done.\n"
     ]
    }
   ],
   "source": [
    "scan_preprocessing(6000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
